version: "3.9"
volumes:
  shared-workspace:
    name: "hadoop-distributed-file-system"
    driver: local

services:
  # Jupyter notebook
  jupyterlab:
    image: jupyter/pyspark-notebook:latest
    container_name: jupyterlab
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - GRANT_SUDO=yes

    ports:
      - 8888:8888
    volumes:
      - shared-workspace:/opt/workspace
    networks:
      - connector

  # Spark Master and Workers
  spark-master:
    image: bde2020/spark-master:latest
    container_name: spark-master
    ports:
      - 8080:8080
      - 7077:7077
    volumes:
      - shared-workspace:/opt/workspace
    networks:
      - connector

  spark-worker-1:
    image: bde2020/spark-worker:latest
    container_name: spark-worker-1
    environment:
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=4g
      - SPARK_MASTER=spark://spark-master:7077
    ports:
      - 8081:8081
    volumes:
      - shared-workspace:/opt/workspace
    depends_on:
      - spark-master
    networks:
      - connector

  spark-worker-2:
    image: bde2020/spark-worker:latest
    container_name: spark-worker-2
    environment:
      - SPARK_WORKER_CORES=4
      - SPARK_WORKER_MEMORY=4g
      - SPARK_MASTER=spark://spark-master:7077
    ports:
      - 8082:8081
    volumes:
      - shared-workspace:/opt/workspace
    depends_on:
      - spark-master
    networks:
      - connector

  # MongoDB
  mongo:
    image: "mongo:latest"
    container_name: mongodb
    volumes:
      - ./mongo/data:/data/db
    networks:
      - connector
    ports:
      - "27017:27017"
    restart: always

networks:
  connector:
    attachable: true
